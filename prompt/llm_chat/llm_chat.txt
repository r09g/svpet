The chatbox should use the art asset from {{$CWD}}/visualization/sprite_sheets/chatbox.png. The chat box consists of two sections. The upper section displays the pet's name and is fixed for a given conversation. The lower section displays the chat text. The text should stay within the boundaries of the chatbox. The text should be white in color, left aligned, and wrap around when reaching the edge of the chatbox. If the length exceeds the height of chatbox, a vertical scroller should be available on the right edge of the chatbox. The chatbox should be directly above the pet, the pixmap of the chatbox and the pet should not overlap.

Double-clicking on the pet pixmap should bring up the chat box. The user should then be able to enter text into the box. If user presses Enter key, this will be wrapped in a chat system prompt and sent to the LLM. This chat system prompt should be used only for the first message after bringing up the chatbox, subsequent messages will be directly sent to the LLM. Once the LLM responds, the user input text in the lower chat box will be replaced with the LLM response. If user clicks on chatbox again, the text response from LLM will be cleared and user can enter next message. During chat when chatbox is open, pet will stay in default or init state for animation. However, user can still drag the pet around, the chatbox and pet pixmaps will act as a single object. Only double-clicking again on the pet will close the chatbox, and the pet will resume its actions and animation.

For all conversations, save the user inputs and LLM responses in a local runtime temporary file. When chatbox is closed by user, send the save system prompt to LLM and save the response to the pet's memory in additional to the basic pet data. This is for condensing and summarizing pet interaction.

The user should be able to connect an offline LLM model through clicking menubar tray icon's Connect LLM option. Then it should ask the user for the path to the model directory. The model should be one downloaded by the user from HuggingFace and loaded using Python.

If no model is connected, the chat will fallback to responding with fixed text for all inputs. The fixed response will be onomatopoeia based on animal type.